Threat : The Paper uses tools like Junit factory, Mutation Score and Line coverage, to generate the automated Unit test cases.
These tools were selected because the base paper of the paper under discussion was also using the same tools. 
Which is not appropriate representation of technological advancements in the same sector rather technological advancement of the tool.

Traces:
Construct validity 

The paper is a reconstruction of its underlying paper and compares the old tools with their newer version for checking the growth , which means that the advancements of tools are a measure of comparision. 
Where as the actual growth of the field is not measured by the growth of the tools but rather the improvement in the technology.

Theory:
As The Base paper is comparing the tools growth to measure the groeth in the field of automation unit testing.It is actually a measure of growth of the tools and not the growth of the field.
This Threat has been adressed by me in my reproduction effort by taking into consideration a new tool which is AI based "Diffblue". 
The tool was compatible with the code and was able to generate Unit test cases and with the increased number of test cases we could see that there has been some improvement in the area.
To further analyse this we now group the test cases under their repective categorise to see if the automation tools have actually surpassed the manual test case generation.
Furthermore a comparison between how the tools approch have changed over time has been compared to see the devlopment in the field.

Feasibility:
As an indepth analysis would mean reading all the generated test cases and classifying them under categorieswhich would mean going through 100 test case per class with a total of 20 classes.
Due to time limitations i have restricted the comparision to 3 classes which would mean comparing roughly 300 test cases and also presenting the improvement in the field.

Implimentation:
The comparision between the types of test cases generated gives us a clearer overview of exactly which kind of testing can be acheived using automated test.As we already know that the coverage has improved.
From our experiment, the next step is to analyze what changes have been made in the field , to get an overview of how the tools have changed.

Results:

After Grouping the test cases generated automated and manually (Page two of observed results excelsheet) we see:
1. Automation tools are unable to provide functional test cases for a given peice of code.
2. Better code coverage is provided by automation tools
3. Better test coverage is provided by automation tools.
4. Automation tools treat the code as a black box and check for outcomes
5. With a perfectly defined code with pre defined assertions automated unit test tools can provide a good coverage.

We finally come to a conclusion that Automated testing might have a good coverage but to acheive a perfect test structure  manual and automation testing both are needed as the functional and white box tests can not be performed with the automation tools.


Requirements:
Same as assingment two as the experiment was performed in assingment 2

Process: 
Same as assingment two as the experiment was performed in assingment 2, the categorisation guidelines for test cases  have been provided in the excel sheet on the same page.

Data:
The data used in the Assingment 3 is a derivative of results from assingment 2 and hence the newly generated data is placed in data folder which includes the comparision and grouping of test cases.
The theoritical understanding of how the tools have improved is added to a power point presentation.